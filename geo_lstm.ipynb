{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from geopy.distance import geodesic # геодезическое расстояние между точками по поверхности Земли\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential  # Для создания и обучения последовательных нейронных сетей\n",
    "from keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# первичная обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df = df.loc[:len(df)//100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.dropoff_longitude.min(), df.dropoff_longitude.max()), (df.dropoff_latitude.min(), df.dropoff_latitude.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['dropoff_latitude']<=90) & (df['dropoff_latitude']>=-90) & (df['dropoff_longitude']<=90) & (df['dropoff_longitude']>=-90)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime']).dt.tz_convert(None)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ['dropoff_longitude', 'dropoff_latitude']\n",
    "imp = IterativeImputer(random_state=42)\n",
    "\n",
    "for row in tqdm(lst):\n",
    "    df[row] = imp.fit_transform(df[row].to_numpy().reshape(len(df), 1))\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engeneering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# расстояние до центра города\n",
    "moscow_center = (40.646746, -73.789962) # аэропорт нью-йорка\n",
    "df['distance_to_moscow_center'] = df.apply(lambda row: geodesic((row['dropoff_latitude'], row['dropoff_longitude']), moscow_center).km, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кластеризация K-средних\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "df['cluster'] = kmeans.fit_predict(df[['dropoff_latitude', 'dropoff_longitude']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Признаки синус-косинус для направления\n",
    "df['lat_sin'] = np.sin(np.radians(df['dropoff_latitude']))\n",
    "df['lat_cos'] = np.cos(np.radians(df['dropoff_latitude']))\n",
    "df['lon_sin'] = np.sin(np.radians(df['dropoff_longitude']))\n",
    "df['lon_cos'] = np.cos(np.radians(df['dropoff_longitude']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = 1\n",
    "df['indicator'] = df.apply(lambda row: int((row['distance_to_moscow_center'] <= dist)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем новые колонки\n",
    "df['minute'] = df['pickup_datetime'].dt.minute\n",
    "df['hour'] = df['pickup_datetime'].dt.hour\n",
    "df['day'] = df['pickup_datetime'].dt.day\n",
    "df['month'] = df['pickup_datetime'].dt.month\n",
    "df['year'] = df['pickup_datetime'].dt.year\n",
    "df.drop(columns=['pickup_datetime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# подготовка данных для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['fare_amount', 'key']).to_numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['fare_amount'].to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.max(), y.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_bins = pd.qcut(y, q=10, precision=1, labels=False)\n",
    "quantile_bins.head(), quantile_bins.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=quantile_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# создание модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изменим размерность для корректной работы модели с архитектурой \"LSTM\"\n",
    "X_train_keras = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_keras = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Иницилизируем модель\n",
    "keras_model = Sequential()\n",
    "keras_model.add(BatchNormalization()) \n",
    "keras_model.add(Bidirectional(LSTM(50, activation='relu', input_shape=(X_train_keras.shape[1], X_train_keras.shape[2]))))\n",
    "keras_model.add(Dropout(0.2))\n",
    "keras_model.add(Dense(1))\n",
    "keras_model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение наилучшей модели\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='keras_model.keras',\n",
    "        # Путь по которому нужно сохранить модель\n",
    "        # Два параметра ниже значат что мы перезапишем\n",
    "        # текущий чекпоинт в том и только в том случае, когда\n",
    "        # улучится значение `val_loss`.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=100)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучим модель\n",
    "keras_model.fit(X_train_keras, y_train, epochs=10, batch_size=64, callbacks=callbacks, validation_data=(X_test_keras, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка лучшей модели\n",
    "keras_model = keras.models.load_model('keras_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions =  keras_model.predict(X_test_keras) # предсказываем валидационную выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, predictions, squared=False), mean_squared_error(y_test, predictions), r2_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchDataset(Dataset):\n",
    "    def __init__(self, X, y): \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dataset = TorchDataset(X = torch.FloatTensor(X_train),\n",
    "                            y = torch.FloatTensor(y_train))\n",
    "t_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_dataset = TorchDataset(X = torch.FloatTensor(X_test),\n",
    "                            y = torch.FloatTensor(y_test))\n",
    "v_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tloader = DataLoader(t_dataset, batch_size=64)\n",
    "next(iter(tloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vloader = DataLoader(v_dataset, batch_size=64)\n",
    "next(iter(vloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size=17, hidden_size=512, bidirectional=True, batch_first=True)\n",
    "        self.x_dense = torch.nn.Linear(1024, 1024)\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        self.fc = torch.nn.Linear(1024, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape((x.shape[0], 1, x.shape[-1]))\n",
    "\n",
    "        x, _ = self.lstm(x)\n",
    "        # print(x.shape)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.x_dense(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        y = self.fc(x)\n",
    "        y = y.squeeze()\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример входных данных\n",
    "torch_model(next(iter(tloader))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model.to(device)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(torch_model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    loss_all = 0\n",
    "    torch_model.train()\n",
    "    for X, y in tqdm(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = torch_model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_all += loss.item()\n",
    "    return f'Train MSE: {loss_all / len(dataloader)}'\n",
    "\n",
    "def test(dataloader):\n",
    "    loss_all = 0\n",
    "    torch_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = torch_model(X)\n",
    "            loss_all += loss_fn(pred, y).item()\n",
    "    return f'Test MSE: {loss_all / len(dataloader)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # clear_output()\n",
    "    print(text)\n",
    "    text = f'Epoch {epoch+1}\\n{train(tloader)}\\n{test(vloader)}'\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model.to('cpu')\n",
    "torch.save(torch_model, 'torch_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = torch.load('torch_model.pth')\n",
    "torch_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## создание предикта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.read_csv('test.csv')\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['pickup_datetime'] = pd.to_datetime(pred_df['pickup_datetime']).dt.tz_convert(None)\n",
    "pred_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# расстояние до центра города\n",
    "moscow_center = (40.646746, -73.789962)\n",
    "pred_df['distance_to_moscow_center'] = pred_df.apply(lambda row: geodesic((row['dropoff_latitude'], row['dropoff_longitude']), moscow_center).km, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кластеризация K-средних\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "pred_df['cluster'] = kmeans.fit_predict(pred_df[['dropoff_latitude', 'dropoff_longitude']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Признаки синус-косинус для направления\n",
    "pred_df['lat_sin'] = np.sin(np.radians(pred_df['dropoff_latitude']))\n",
    "pred_df['lat_cos'] = np.cos(np.radians(pred_df['dropoff_latitude']))\n",
    "pred_df['lon_sin'] = np.sin(np.radians(pred_df['dropoff_longitude']))\n",
    "pred_df['lon_cos'] = np.cos(np.radians(pred_df['dropoff_longitude']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = 1\n",
    "pred_df['indicator'] = pred_df.apply(lambda row: int((row['distance_to_moscow_center'] <= dist)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем новые колонки\n",
    "pred_df['minute'] = pred_df['pickup_datetime'].dt.minute\n",
    "pred_df['hour'] = pred_df['pickup_datetime'].dt.hour\n",
    "pred_df['day'] = pred_df['pickup_datetime'].dt.day\n",
    "pred_df['month'] = pred_df['pickup_datetime'].dt.month\n",
    "pred_df['year'] = pred_df['pickup_datetime'].dt.year\n",
    "pred_df.drop(columns=['pickup_datetime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.drop(columns=['key'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "предикт для кераса делается также как для catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "\n",
    "for i in tqdm(range(len(pred_df))):\n",
    "    pred.append(torch_model(torch.FloatTensor(pred_df.loc[i].to_numpy().reshape(1,1,17)).to(device)).cpu().item())\n",
    "\n",
    "len(pred), pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('sample_submission.csv')\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['fare_amount'] = pred\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv('sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
